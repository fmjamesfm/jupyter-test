{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3ccb05-89ec-4359-9473-f187d96eea2a",
   "metadata": {},
   "source": [
    "# Fourier analysis\n",
    "$$\\newcommand{\\sinn}{\\sin\\left(\\frac{n\\pi}{L} x\\right)} \\newcommand{\\cosn}{\\cos\\left(\\frac{n\\pi}{L} x\\right)} \\newcommand{\\diff}{\\mathop{}\\!\\mathrm{d}}$$ \n",
    "\n",
    "## Pre-requisites\n",
    "The notebook on [complex numbers](Complex.ipynb) is required reading before this one.\n",
    "\n",
    "Useful reading:\n",
    "\n",
    "* Fourier Series by G.P. Tolstov\n",
    "\n",
    "## The Fourier series\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "f(x) = \\frac{a_0}{2} + \\sum_{n=1}^\\infty \\left[a_n\\cosn + b_n \\sinn\\right] \\tag{1}\n",
    "}$$\n",
    "\n",
    "This is a Fourier series expansion of a function $f(x)$ over the interval $[-L,L]$. Equivalently, it represents a periodic function with period $T=2L$. It expresses such function as an infinite sum of sine and cosine functions, one for each integer $n \\in \\{1,2,3,...\\}$, and each with with its own weighting constant $a_n$ and $b_n$. Looking at Eq. 1, we should see that each of the coefficients $a_n$ and $b_n$ tells us how much of $\\cosn$ and $\\sinn$ respectively are present in $f(x)$. If we pick a single value of $n$ we would have $f_n(x)$:\n",
    "\n",
    "$$\n",
    "f_n(x)=a_n\\cosn + b_n \\sinn\n",
    "$$\n",
    "\n",
    "The weightings (or coefficients) can be obtained by the following integrals of the function $f(x)$ with each sine and cosine component in the series, one by one:\n",
    "\n",
    "$$a_n = \\frac{1}{L} \\int_{-L}^{L} f(x) \\cosn \\diff x \\tag{2} $$\n",
    "$$b_n = \\frac{1}{L}\\int_{-L}^{L} f(x) \\sinn \\diff x \\tag{3} $$\n",
    "\n",
    "We should see that for $n=0$, sines and cosine terms would be constant, with $\\sin(0)=0$ and $\\cos(0)=1$, so the zeroth coefficient $a_0$ is shown separately and is halved for reasons that should become clear once we have understood how these formulas come about and what they really mean.\n",
    "\n",
    "You can see in the code below that many shapes can be represented with only a few sine and cosine components. See if you notice any interesting symmetries when picking only sines or only sines or mixtures of both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad9361b-cbf7-4584-bcd4-377b163396dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5055656dcd458091d0f6ec071d0baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(FloatSlider(value=0.5, description='a0', max=1.0, min=-1.0), Floa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from ipywidgets import interact, widgets\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(-2, 2, 200)\n",
    "\n",
    "N = 5 # maximum coefficient n\n",
    "\n",
    "def change_coefficients(**kwargs):\n",
    "    fig, (ax1, ax2)=plt.subplots(nrows=2, sharex='col')\n",
    "\n",
    "    total = 0 \n",
    "    \n",
    "    for item, value in kwargs.items():\n",
    "        term  = value * np.cos(int(item[1])*np.pi*x) * (item[0]=='a') + value * np.sin(int(item[1])*np.pi*x) * (item[0]=='b')\n",
    "        total = total + term \n",
    "        \n",
    "        ax1.plot(x, term, label=item)\n",
    "    \n",
    "    ax2.plot(x, total, 'k')\n",
    "    \n",
    "    ax2.grid()\n",
    "    ax1.grid()\n",
    "    ax1.set_title('Individual harmonics')\n",
    "    ax2.set_title('Sum')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "sa = [widgets.FloatSlider(description='a{}'.format(n), min=-1, max=1, step=0.1, value=0.5) for n in range(N+1)]\n",
    "sb = [widgets.FloatSlider(description='b{}'.format(n), min=-1, max=1, step=0.1, value=0) for n in range(1,N+1)]\n",
    "\n",
    "# Link sliders to function\n",
    "out = widgets.interactive_output(change_coefficients, {**{f'a{i}': s for i, s in enumerate(sa)}, **{f'b{i+1}': s for i, s in enumerate(sb)}})\n",
    "\n",
    "# Layout sliders in two rows\n",
    "col1 = widgets.VBox(sa)\n",
    "col2 = widgets.VBox(sb)\n",
    "inputlayout = widgets.HBox([col1, col2])\n",
    "layout = widgets.VBox([inputlayout, out])\n",
    "\n",
    "# Display everything\n",
    "display(layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d675ba-47a3-490c-bb37-c2a004270b03",
   "metadata": {},
   "source": [
    "## Orthogonality \n",
    "\n",
    "The Fourier series is a particular case of a more general expansion of $f(x)$ over the interval $[a,b]$ into a series of mutually *orthogonal basis* functions $\\varphi_n(x)$, with weightings $c_n$:\n",
    "\n",
    "$$f(x)=c_0\\varphi_0\\left(x \\right) + c_1\\varphi_1\\left(x \\right) + c_2\\varphi_2\\left(x \\right) + ... = \\sum_{n=0}^\\infty c_n \\varphi_n\\left(x \\right) \\tag{4} $$ \n",
    "\n",
    "By definition, two (real) functions are orthogonal if their *inner product*, defined as \n",
    "$$\\langle f(x) \\, , g(x) \\rangle=\\int_a^b f(x)g(x) \\diff x$$ \n",
    "is zero. So for the functions $\\varphi_n(x)$ to be orthogonal, they must satisfy:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\langle \\varphi_m(x) \\, , \\varphi_n(x) \\rangle = \\int_{a}^{b}\\varphi_m\\left(x \\right) \\cdot \\varphi_n\\left(x \\right) \\diff x = 0 && \\text{for } m\\neq n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "For $m=n$ the inner product gives a finite, positive constant $C^2$:\n",
    "$$\n",
    "\\langle \\varphi_m, \\varphi_m \\rangle = \\int_a^b \\varphi_m^2(x) \\, dx = C^2\n",
    "$$\n",
    "\n",
    "\n",
    "Eq. 4 is much like representing $f(x)$ in a coordinate system. We are used to vectors in 3D space being constructed as the sum of 3 orthogonal basis vectors, like the unit vectors $\\hat{\\mathbf{x}}$, $\\hat{\\mathbf{y}}$ and $\\hat{\\mathbf{z}}$, pointing in each of the three axes: \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}} = (1, 0, 0),\\quad \\hat{\\mathbf{y}} = (0,1,0),\\quad \\hat{\\mathbf{z}} = (0,0,1)\n",
    "$$\n",
    "\n",
    "Some vector $\\vec{A}$ can be expressed as the sum of the basis vector, each weighted by a coefficient $c_{1,2,3}$:\n",
    "\n",
    "$$\n",
    "\\vec{A}=c_1 \\hat{\\mathbf{x}} + c_2 \\hat{\\mathbf{y}} + c_3 \\hat{\\mathbf{z}}\n",
    "$$\n",
    "\n",
    "The inner product of any pair of these basis vectors is zero, hence we say they are orthogonal (they are at right angles from each other):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle\\hat{\\mathbf{i}}\\,,\\hat{\\mathbf{y}}\\rangle &= \\sum_{n=1}^{3} \\hat{\\mathbf{x}}_n \\cdot \\hat{\\mathbf{y}}_n = 1\\cdot 0 + 0 \\cdot 1 + 0 \\cdot 0 = 0 \\\\\n",
    "\\langle\\hat{\\mathbf{x}}\\,,\\hat{\\mathbf{z}}\\rangle&= 0\\\\\n",
    "\\langle\\hat{\\mathbf{y}}\\,,\\hat{\\mathbf{z}}\\rangle&= 0\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The inner product has a very clear geometrical interpretation: it is the length of the projection of a vector onto another. Its result depends on the angle $\\theta$ between them: if they are aligned, the angle $\\theta$ is zero and the projection has its maximum length, while it zero if the angle is 90 degrees:\n",
    "\n",
    "$$\n",
    "\\langle \\vec{A}, \\vec{B} \\rangle = \\|\\vec{A}\\| \\|\\vec{B}\\| \\cos \\theta\n",
    "$$\n",
    "\n",
    "The inner product of a vector with itself results in the square of its norm (its magnitude or length squared):\n",
    "\n",
    "$$\n",
    "\\langle\\hat{\\mathbf{x}}\\,,\\hat{\\mathbf{x}}\\rangle  = \\|\\hat{\\mathbf{x}}\\|^2 = 1\n",
    "$$\n",
    "\n",
    "This value is equal to one when we're dealing with unit vectors, for any other vector it results in some constant $C^2$ representing its length squared:\n",
    "\n",
    "$$\n",
    "\\langle\\vec{A}\\,,\\vec{A}\\rangle = \\|\\vec{A}\\|^2 = C^2 \n",
    "$$\n",
    "\n",
    "Carrying out the inner product of $\\vec{A}$ with any of the (unit) basis vectors will return its corresponding weighting **alone**:\n",
    "\n",
    "$$\n",
    "\\langle\\vec{A}\\,,\\hat{\\mathbf{x}}\\rangle = c_1\n",
    "$$\n",
    "This is quite easy to see by the definitions of $\\hat{\\mathbf{x}}, \\hat{\\mathbf{y}}, \\hat{\\mathbf{z}}$, since they point in the three cardinal directions their respective off-axis components are zero. \n",
    "\n",
    "Eq. 4 is the analogous operation in function space: the basis \"vectors\" are the functions $\\varphi_n(x)$, and they are infinite in number (we went from three to infinite dimensions). The powerful idea is that by multiplying both sides by one of the functions $\\varphi_m$, and by integrating over the interval $[a,b]$, we end up carrying out a term-by-term inner product. By the properties of $\\varphi_n$ we find that all but one term (where $m=n$) will vanish:\n",
    "\n",
    "$$\n",
    "f(x)\\cdot\\varphi_m(x) = c_0 \\varphi_0(x) \\cdot \\varphi_m(x) + c_1 \\varphi_1(x) \\cdot \\varphi_m(x) + c_2 \\varphi_2(x) \\cdot \\varphi_m(x) + ... + c_m {\\color{Red}\\varphi_m^2(x)} + ... \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\langle f(x)\\,,\\varphi_m(x)\\rangle = \\int_{a}^{b} f(x)\\cdot\\varphi_m(x) \\diff x= c_0 \\int_{a}^{b}  \\varphi_0(x) \\cdot\\varphi_m(x) \\diff x+ c_1\\int_{a}^{b}  \\varphi_1(x) \\cdot\\varphi_m(x) \\diff x + ... + c_m\\int_{a}^{b}  {\\color{Red}\\varphi_m^2(x)} \\diff x + ... \n",
    "$$\n",
    "\n",
    "Since $\\int_{a}^{b}\\varphi_m \\cdot \\varphi_n \\diff x = 0$ where $m\\neq n$, we can now recover the individual coefficient $c_m$:\n",
    "\n",
    "$$ c_m = \\frac{1}{C^2}\\int_{a}^{b} f(x)\\cdot\\varphi_m \\diff x $$\n",
    "\n",
    "In other words, by the inner product $\\langle f(x) \\, , \\varphi_m \\rangle$ we know how much of $\\varphi_m$ is in the function $f(x)$. \n",
    "\n",
    "## Orthogonality of cosines and sines\n",
    "Returning to the Fourier series as shown in Eq. 1, we know that we're dealing with an expression like Eq. 4, because the functions $\\cosn$ are indeed orthogonal to each other over the interval $[-L, L]$, since:\n",
    "\n",
    "$$\n",
    "\\left\\langle \\cos\\left(\\frac{m\\pi x}{L}\\right) \\,, \\cos\\left(\\frac{n\\pi x}{L}\\right)\\right\\rangle = \\int_{-L}^L \\cos\\left(\\frac{m\\pi x}{L}\\right) \\cos\\left(\\frac{n\\pi x}{L}\\right) dx =\n",
    "\\begin{cases}\n",
    "0 & \\text{if } m \\ne n \\\\\n",
    "L & \\text{if } m = n \\ne 0 \\\\\n",
    "2L & \\text{if } m = n = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "We call these *orthogonality relations*. There is a small difference between our general $\\varphi_m$ set and these cosine shapes: where $m=n=0$ the cosine inner product is $2L$ rather than simply $L$. We otherwise have that:\n",
    "\n",
    "* The general basis functions become cosine terms:\n",
    "$$\\varphi_n(x) = \\cos\\left(\\frac{n\\pi x}{L}\\right)$$\n",
    "* The inner product norm becomes $L$\n",
    "$$\\langle\\varphi_n\\,,\\varphi_n\\rangle = L \\quad \\text{for } n\\ne 0$$\n",
    "$$\\langle\\varphi_0\\,,\\varphi_0\\rangle = 2L $$\n",
    "* The domain becomes:\n",
    "$$\n",
    "[a,b] =[-L, L]\n",
    "$$\n",
    "\n",
    "The sine functions $\\sinn$ are similarly orthogonal over $[-L,L]$, and additionally, each $\\cosn$ is orthogonal to each $\\sinn$ (you could try to verify this fact). These two families together form a complete, orthogonal system. Hence the coefficients $a_n$ and $b_n$ can be obtained separately and individually by integration, as shown in Eq. 2 and 3. \n",
    "\n",
    "In short, by the inner products of the function $f(x)$ with each of the basis functions $\\sinn$ and $\\cosn$ (shown in Eq. 2 and 3), we **separately** and **independently** recover how much of each of the oscillatory terms $\\sinn$ and $\\cosn$ are contained in $f(x)$. We are extracting individual frequency components of the function $f(x)$ contained in the interval $[-L, L]$.\n",
    "\n",
    "The $a_0/2$ term in the series corresponds to the average (DC) level of the function $f(x)$; it results from the inner product of $f(x)$ with the zeroth cosine term (a constant term, since $\\cos0=1$). The average value of the function over $[-L,L]$ is in fact:\n",
    "\n",
    "$$\n",
    "\\frac{1}{{\\color{Red}2 }L}\\int_{-L}^L f(x) \\diff x = \\frac{a_0}{2}\n",
    "$$\n",
    "\n",
    "We halve the coefficient $a_0/2$ by convention, so that $a_0$ is obtained the same way as other coefficients (using Eq. 2). This is because the corresponding inner product for $n=m=0$ would give us $2L$ instead of $L$:\n",
    "\n",
    "$$\n",
    "\\int_{-L}^L \\cos^2(0) \\diff x = \\int_{-L}^L 1 \\diff x= {\\color{Red}2}L\n",
    "$$\n",
    "\n",
    "\n",
    "All of this so far may not seem readily applicable, but I hope that by reading through this notebook and playing with the code it will become clearer how this came about, and why it can be an invaluable tool in your arsenal. With Fourier analysis, we have a means of easily solving partial differential equations, extracting frequency information from signals, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a90234b-357c-4971-9342-092e909b9b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a85f9c052743a2a61e4be3feea9bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=3.0, description='m', max=15.0, min=1.0, step=1.0), FloatSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,1, 200)\n",
    "\n",
    "def change_coefficients(m,n):\n",
    "\n",
    "    fig, (ax1,ax2) =plt.subplots(nrows=2, sharex='col')\n",
    "    ax1.set_ylim((-1.1,1.1))\n",
    "    ax2.set_ylim((-1.1,1.1))\n",
    "    \n",
    "    ax1.set_title('')\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "    \n",
    "    f = np.sin(m*np.pi*x)\n",
    "    g = np.sin(n*np.pi*x)\n",
    "    fg = f*g\n",
    "    \n",
    "    ax1.plot(x, f, 'b', label=r'$f(x)=\\sin(m\\pi x)$')\n",
    "    ax1.plot(x, g, 'r', label=r'$g(x)=\\sin(n\\pi x)$')\n",
    "\n",
    "    ax2.plot(x, fg, 'k', label=r'$f(x)\\cdot g(x)$')\n",
    "    ax2.fill_between(x, fg, where=fg>0, color='b')\n",
    "    ax2.fill_between(x, fg, where=fg<0, color='r')\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='lower left')\n",
    "\n",
    "    ax2.axhline(0, color='k')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "interact(change_coefficients, m=widgets.FloatSlider(min=1, max=15, step=1, value=3, description='m'), \n",
    "         n=widgets.FloatSlider(min=1, max=15, step=1, value=1, description='n'),\n",
    "        );\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356cb9b-b981-4f27-bd69-ad68c88b4c8a",
   "metadata": {},
   "source": [
    "\n",
    "## A little history\n",
    "\n",
    "A good way to understand Fourier series (and eventually transforms) is to go back to its origins. Before Joseph Fourier came to the scene, it was already known, thanks to Daniel Bernoulli and Euler among others, that many physical problems could be approached with trigonometric series. For instance, the displacement $u$ along a vibrating string of length $L$, fixed at both ends $x=0$ and $x=L$, can be represented as an infinite sum of its natural mode shapes:\n",
    "\n",
    "$$\n",
    "u(x) = \\sum_{n=1}^\\infty b_n \\sinn\n",
    "$$\n",
    "\n",
    "with mode numbers $n\\in \\{1, 2, 3, ...\\}$. Whether sines or cosines or mixtures of both appear in a Fourier series depends on the boundary conditions, or equivalently, on the symmetry of the function. We'll explore that later, but perhaps you can already tell why the displacement along such a string is represented as a sum of sines only.\n",
    "\n",
    "Unsurprisingly, Fourier spent a lot of time playing with trigonometric series, expressing functions in terms like these:\n",
    "\n",
    "$f(x)=a_0+a_1\\cos(\\pi x) + a_2\\cos(2\\pi x) + ...$ \n",
    "\n",
    "And finding that he could recover each coefficient by the inner product of $f(x)$ with $\\cos(n\\pi x)$ (here the integration interval would be $x=[-1,1]$).\n",
    "\n",
    "Fourier's radical leap was to suggest that *any* function (even discontinuous and not very nice ones) could be expressed as an infinite trigonometric sum with a combination of sine and cosine. This was fairly controversial at the time (and formal proof of this would come much later through Dirichlet, Riemann and others), so Fourier was subject to some criticism from his peers for lack of rigour. It was clear to everyone involved that these series and integrals were often poorly behaved.\n",
    "\n",
    "Nonetheless, he developed what is now called Fourier analysis, while studying heat flow, culminating in his influential book [The Analytical Theory of Heat](https://www.cambridge.org/core/books/analytical-theory-of-heat/F6D4802336FABD1116DDA4AA3FE6EFAA). The modern foundations for this topic were born out of his work on the heat equation, a partial differential equation (PDE) that describes how the temperature $u$ in some material evolves over time.\n",
    "\n",
    "## Solving the heat equation \n",
    "\n",
    "Here is the heat equation in one spatial dimension $x$ (to keep things simple). In one dimension it could describe how temperature $u$ varies along a rod:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{\\partial u}{\\partial t} = D \\frac{\\partial^2 u}{\\partial x^2}\n",
    "}$$\n",
    "\n",
    "This is the diffusion equation (a *parabolic* PDE), and the constant $D$ is the diffusion coefficient (*thermal diffusivity*), a property of the medium, which tells us how quickly heat (in our case) spreads through the material. This kind of equation applies to many diffusion-type phenomena, including diffusion of sound energy (e.g. in statistical room acoustics). We won't spend too much time on the physical interpretation but rather focus on Fourier's mathematical approach. We could already discretise the problem and solve a particular situation numerically (and you can find an approach in the notebook on [Waves](Waves.ipynb)), but we will take the analytical route.\n",
    "\n",
    "We'll use the method of *separation of variables* to solve this equation. This means assuming that the temperature $u$ is composed of the product of two independent terms: one being purely time dependent, and one being purely space dependent:\n",
    "\n",
    "$$u=X(x)\\cdot T(t)$$\n",
    "\n",
    "If this seems like a wild guess, it's because it is. It may seem needlessly restrictive, ruling out a lot of possible behaviours. But keep in mind that we're dealing with a *linear* differential equation that admits multiple (even infinite) solutions (by *superposition*). In fact (**spoiler alert**) the full solution ends up being a sum of such separable solutions:\n",
    "\n",
    "$$u(x,t) = X_1(x)T_1(t) + X_2(x) T_2(t) + X_3(x)T_3(x) + ...$$ \n",
    "\n",
    "so that each shape $X_n(x)$ has its own distinct time dependence $T_n(t)$. The result is complex behaviour that can track experimental results to high degree of accuracy. Separation of variables has its limitations, as while it can work for more than one spatial dimensions, it is restricted to specific geometries (e.g. exhibiting high symmetry like rectangular, cylindrical, etc). \n",
    "\n",
    "So, if we plug this form of $u=X(x)T(t)$ into the heat equation, we find that we can neatly separate the time and space dependent parts on either side of the equation. This is because $T(t)$ is constant under differentiation over $x$, and vice-versa $X(x)$ is constant when differentiating over $t$. So we get:\n",
    "\n",
    "$$\n",
    "D\\frac{X''(x)}{X(x)}=\\frac{T'(t)}{T(t)}\n",
    "$$\n",
    "\n",
    "Here the prime indicates differentiation (and double prime is differentiating twice). The trick to continuing here is to think that since the left hand side cannot vary with time, the right hand side must not either! This means $T'/T$ is constant, and so is $X''/X$ and they are equal. We will name this constant  $\\lambda$:\n",
    "\n",
    "$$\n",
    "D\\frac{X''(x)}{X(x)}=\\frac{T'(t)}{T(t)}=\\lambda\n",
    "$$\n",
    "And now we have two equations:\n",
    "\n",
    "$$\n",
    "X''(x)=\\frac{\\lambda}{D} X(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "T'(t)=\\lambda T(t)\n",
    "$$\n",
    "\n",
    "These are now ordinary differential equations (ODEs) and can be solved independently and more easily. The spatial equation is of second order, the one for time is first order which should be easiest to start with. Here we're looking for a function $T(t)$ that, when differentiated once, returns itself times a constant. The exponential $e^{\\lambda t}$ fits the bill, and this is so by definition! $e^x$ is the function that satisfies $f(x)=f'(x)$. And \n",
    "$$\\frac{\\diff }{\\diff t}e^{\\lambda t} = \\lambda e^{\\lambda t} $$\n",
    "\n",
    "So we've found half of the solution $$u=X(x)\\cdot e^{\\lambda t}$$ \n",
    "\n",
    "Not bad. However, there's a little problem: $\\lambda$ can't physically be a positive number. \n",
    "\n",
    "If $\\lambda$ is positive, the temperature will increase exponentially over time, which would violate energy conservation: we're adding free energy over time into the system, when we expect it to be dissipated. $\\lambda>0$ is still mathematically valid, but not physical! \n",
    "\n",
    "Let's go back, and to make things easier to interpret we introduce a negative sign, and assume that $\\lambda$ is a positive physical quantity. This fixes our time dependence (this also has some interesting consequences to the space dependent equation). The time dependence is now:\n",
    "\n",
    "$$\n",
    "T'(t)=-\\lambda T(t) \\tag{5}\n",
    "$$\n",
    "\n",
    "So now $T(t)=e^{-\\lambda t}$ and we're happy. Well, almost. We can see that temperature will decay exponentially over time for $\\lambda>0$ and remain constant over time for $\\lambda=0$. We still have no idea what $\\lambda$ is, and for this to be any use we ought to find out how quickly the temperature will decay.\n",
    "\n",
    "There could be some unknown constant in the mix, so that $T(t)=C e^{\\lambda t}$. But since $u=X(x)T(t)$, a constant factor could sit either in $X(x)$ or $T(t)$ so we can decide that $C=1$ and $T(t)=e^{-\\lambda t}$ and deal with it later when solving for $X(x)$. \n",
    "\n",
    "Where the Fourier series comes into play is through $X(x)$. For simplicity let's introduce another constant $k^2=\\lambda/D$. And here's our ODE for the spatial dependence:\n",
    "\n",
    "$$\n",
    "X''(x)=- k^2 X(x) \\tag{6}\n",
    "$$\n",
    "\n",
    "So the temperature distribution along this rod needs to be a function whose second derivative is equal to itself (times a negative constant). This is a property that the sine and cosine functions have, so they should work as valid values of $X(x)$. It may seem strange to jump to a solution like this, but as you may have seen by now, wild guessing is the name of the game.\n",
    "So we plug in a wild guess, $X(x) = \\sin(k x)$ and we get:\n",
    "\n",
    "$$\\frac{d^2 \\sin(k x)}{dx^2} = -k^2 \\sin (k x)$$ \n",
    "\n",
    "This works. And now we try $\\cos(k x)$ instead:\n",
    "\n",
    "$$\\frac{d^2 \\cos(k x)}{dx^2} = -k^2 \\cos (k x)$$\n",
    "\n",
    "This works too. The argument of cosine and sine could also have an additional constant, like $\\cos(k x + \\phi)$, since on differentiation, $\\phi$ doesn't come out of the argument of the cosine (using the chain rule): \n",
    "\n",
    "$$\\frac{d^2\\cos(k x + \\phi)}{dx^2}=-k^2\\cos(k x + \\phi)$$\n",
    "\n",
    "And that's still a valid solution.\n",
    "\n",
    "Somewhat surprisingly, the exponential $e^{k x}$ doesn't work!\n",
    "\n",
    "$$\\frac{d^2 e^{k x}}{dx^2} = {\\color{Red}+}k^2 e^{k x}$$\n",
    "\n",
    "The sign ends up wrong on the RHS. So surely flipping the sign of the exponent would? No. Plugging in $e^{-k x}$ still results in a plus sign on the RHS after double differentiation since $(-k)^2=+k^2$.\n",
    "\n",
    "But inserting the imaginary unit $i$ into the exponent $e^{ik x}$ (or $e^{-ik x}$) does work, as the sign will flip correctly after differentiating twice (because $i^2=-1$ of course)! \n",
    "\n",
    "$$\\frac{d^2 e^{ik x}}{dx^2} = -k^2 e^{ik x}$$\n",
    "\n",
    "We know (thanks to Euler's hard work) that $e^{ix}$ is oscillatory for varying $x$, being a combination of a cosine of $x$ (real part) and a sine of $x$ (the imaginary part), so we can see why that worked. ([See the notebook on complex quantities which is best to have looked at first](Complex.ipynb))\n",
    "\n",
    "Now we have some solutions, including a complex one. By superposition, any linear combination of valid solutions for $X(x)$ also works. We only need two linearly independent solutions (which sine and cosine are) for a complete general solution to a second order ODE. So we'll stick with real values and the general solution is: \n",
    "\n",
    "$$X(x)=A\\cos(k x) + B\\sin(k x)$$\n",
    "\n",
    "Here we have some unknown constants $A$ and $B$.  \n",
    "\n",
    "You can try plugging this into Eq. 6 and you will see it all checks out, since differentiation applies separately to each component of the sum in this linear system.\n",
    "\n",
    "We have to remember that we haven't pinned down a value for $k$, since $\\lambda$ isn't known. There could be multiple valid values of $k$, and this will depend on any additional constraints we put on the system. If $k$ could only have certain discrete values, then a valid solution could end up being an infinite series, like:\n",
    "\n",
    "$$\n",
    "X(x)=\\sum_{n=0}^{\\infty}\\left(A_n \\cos(k_n x) + B_n \\sin (k_n x)\\right)\n",
    "$$\n",
    "\n",
    "The temperature distribution could be an infinite sum of sines and cosines. Looks a lot like our Fourier series from Eq. 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bbb6d3-0215-4ce5-ad7a-74129a3fc911",
   "metadata": {},
   "source": [
    "## The finite rod of length $L$ and the Fourier sine series\n",
    "\n",
    "So we have potentially infinite solutions at the moment, though we know that a physical problem ought to have just one answer. To find a particular solution to a particular problem we need to specify initial and boundary conditions so we can narrow things down. After all, what the temperature looks like along a material will depend on the situation.\n",
    "\n",
    "We might say that our rod is finite, of length $L$ and that $u=0$ at $x=0$ and $x=L$. This way we're fixing the temperature at both ends of the rod (by fixing zeroes at the boundaries we are technically applying *Dirichlet boundary conditions*). Let's do this by choosing one of the valid solutions above: $X(x)=A\\sin{k x}$. At $x=0$ we have:\n",
    "\n",
    "$$X(0)=A\\sin{(k \\cdot 0)}=0$$\n",
    "\n",
    "This is automatically satisfied by the $\\sin$ function, no matter what $k$ is. So $X=A \\sin(k x)$ is a solution! We were a little lucky here that we picked the right form immediately. But we have no idea what $k$ or $A$ are. So off we go to the other end of the rod, $x=L$:\n",
    "\n",
    "$$X(L)=A\\sin{(k \\cdot L)}=0$$\n",
    "\n",
    "Now we're in slight trouble, because there are multiple (discrete) values of $k$ that fulfill this condition, but at least we know what they are:\n",
    "\n",
    "$$\n",
    "k_n \\in \\left\\{\\frac{\\pi}{L}, \\frac{2 \\pi}{L}, \\frac{3\\pi}{L}, ...\\right\\}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "k_n = \\frac{n \\pi}{L}\n",
    "$$\n",
    "\n",
    "for each $n \\in \\{ 1, 2, 3, ... \\}$\n",
    "\n",
    "\n",
    "The units of $k$ are interesting here: an inverse length. We can call $k$ a spatial frequency, and $\\sin(k_n x)$ the shape of a spatial harmonic, or mode. Now we also have infinite values for the constant $\\lambda$:\n",
    "\n",
    "$$\\lambda_n = D k_n^2 = D\\left(\\frac{n\\pi}{L}\\right)^2$$\n",
    "\n",
    "Technically the shapes $\\sin(k_n x)$ are *eigenfunctions* (the mode shapes) of the spatial ODE, and $k_n^2$ are the *eigenvalues*. The eigenvalues $k_n^2$ here tell us two things: how quickly temperature \"oscillates\" in space, but also how quickly it decays over time at a particular mode, since they end up in the temporal ODE via $\\lambda_n$, $T_n(t)=e^{-\\lambda_n t}$. The two pieces of information are inextricably tied together, since a high curvature (RHS of the heat equation) from rapid oscillation in space implies a faster rate of change in time (LHS of the heat equation).\n",
    "\n",
    "Importantly, for every value of $k_n$ we may have a different constant $A_n$. We can't tell what these constants are as there's not enough information. So, the solution so far is an infinite sum of sines with unknown coefficients $A_n$:\n",
    "\n",
    "$$\n",
    "u=X(x)\\cdot T(t) = \\sum_{n=1}^{\\infty}A_n \\sin\\left(k_n x\\right) \\cdot e^{-D k_n^2 t}\n",
    "$$\n",
    "\n",
    "It has the form that we earlier anticipated:\n",
    "\n",
    "$$u(x,t)=X_1(x)\\cdot T_1(t) + X_2(x)\\cdot T_2(t) + X_3(x)\\cdot T_3(t) + ...$$\n",
    "\n",
    "\n",
    "For completeness, we could have arrived here starting with a more general solution for the spatial dependence:\n",
    "\n",
    "$$X(x)=A\\sin(k x) + B\\cos(k x)$$\n",
    "\n",
    "When fixing the first boundary at $x=0$ to zero we get:\n",
    "\n",
    "$$X(0)=0=A\\sin(k \\cdot 0) + B\\cos(k \\cdot 0)=B$$\n",
    "\n",
    "So we immediately find $B=0$, and our solution is still just $X(x)=A \\sin(k x)$.\n",
    "\n",
    "It's clear $X(x)=B\\cos{k x}$ on its own doesn't work (you can try) unless $B=0$ and temperature is zero everywhere and always. But it could nonetheless be a solution to a slightly different problem! Sine and cosine are after all only 90 degrees apart.\n",
    "\n",
    "Now, back to the final form of $X(x)$:\n",
    "\n",
    "$$\n",
    "X(x)=\\sum_{n=1}^{\\infty}A_n \\sin\\left(\\frac{n\\pi}{L} x\\right)\n",
    "$$\n",
    "\n",
    "This we call a Fourier sine series. This is saying that if $X(x)$ is to satisfy our boundary conditions, it must be representable as an infinite sum of sines. Or, conversely, a function that is the infinite sum of such harmonics automatically satisfies our boundary conditions. We can easily tell that the conditions are satisfied because no matter what $n$ or $L$ are, at $x=0$ and $x=L$ all elements of the sum have a value of zero.\n",
    "\n",
    "\n",
    "Some important features of this particular $X(x)$ at this point: \n",
    "* Since the sine function is odd, the function $X(x)$ must be odd (any sum of odd functions is itself odd).\n",
    "* $X(x)$ is also periodic, with period $T=2L$, since all the elements in the sum are periodic with period $T=2L$.\n",
    "* Higher harmonics, with $n>1$ are periodic over shorter periods, but their arguments are integer multiples of the sine for $n=1$ and thus are still periodic over $2L$.\n",
    "\n",
    "\n",
    "What we have seen so far is that a Fourier series for a function $f(x)$ emerges quite naturally as a solution to the second order linear differential equation of the form:\n",
    "\n",
    "$$f''(x) = -c^2 f(x)$$\n",
    "\n",
    "for some positive constant $c^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b29e7-efee-4ff1-82ae-5c84b3023ca9",
   "metadata": {},
   "source": [
    "$\\newcommand{\\sinm}{\\sin\\left(\\frac{m \\pi}{L} x\\right)}$\n",
    "## Orthogonality of sines\n",
    "\n",
    "So how do we move on from here and get the coefficients $A_n$? We can specify what the temperature looks like initially, at time $t=0$. Let's start by saying that, at time zero, the temperature distribution follows some function $f(x)$. We know this $f(x)$ depends on $x$ only, and since $u(x,0)=X(x) T(0)$. $f(x)$ and $X(x)$ here are the same since we assumed $T(0)=1$: \n",
    "\n",
    "$$\n",
    "u(x,0)=f(x)=X(x)\\cdot T(0) =\\sum_{n=1}^{\\infty}A_n \\sin\\left(\\frac{n\\pi}{L} x\\right)\n",
    "$$\n",
    "\n",
    "We have the function $f(x)$ in terms of the coefficients $A_n$ but finding them still seems hard. Here is where we have to take a little detour into an important property of these mode shapes mentioned previously: orthogonality. \n",
    "\n",
    "Consider the mode funcion  $\\varphi_m(x)=\\sin\\left(\\frac{m \\pi}{L} x\\right)$. The square of $\\varphi_m(x)$ is:\n",
    "\n",
    "$$\\varphi_m^2(x)=\\sin^2\\left(\\frac{m \\pi}{L} x\\right)$$\n",
    "\n",
    "A square of a real number, as we know, is always positive. The area under this sine in the interval $[0,L]$ should then be a finite, positive value:\n",
    "\n",
    "$$\n",
    "\\int_0^L\\varphi_m^2(x) \\diff x=\\int_0^L\\sin^2\\left(\\frac{m \\pi}{L} x\\right) \\diff x=\\frac{L}{2}\n",
    "$$\n",
    "\n",
    "Now consider, instead, that we multiply $\\varphi_m(x)$ with a different index $n\\neq m$: $\\varphi_n(x)=\\sinn$. The arguments of the sine function differ between $\\varphi_m(x)$ and $\\varphi_n(x)$, so the area under the curve of their product is sometimes positive, sometimes negative. As it turns out, the positive and negative areas are equal and sum to zero. The product $\\sinm \\sinn$ can be split into a sum using the relation:\n",
    "\n",
    "$$\n",
    "2\\sin(a)\\sin(b)=\\cos(a+b) - \\cos(a-b)\n",
    "$$\n",
    "And so:\n",
    "$$\n",
    "2\\varphi_m(x) \\varphi_n(x) = 2\\sinm\\sinn=\\cos\\left[(m+n) \\frac{\\pi x}{L}\\right] - \\cos\\left[(m-n) \\frac{\\pi x}{L}\\right]\n",
    "$$\n",
    "\n",
    "From a product of sines we get the simple sum of two cosines at different frequencies. Importantly, since $n-m$ and $n+m$ are integers, they are still periodic over the interval $[-L,L]$, and so $[0,L]$ still represents a multiple of half a cycle. When integrating this expression between $[0,L]$ we separately integrate the two sines which both to zero! So the inner product is zero:\n",
    "\n",
    "$$\\int_0^L \\sinm\\sinn dx = \\int_0^L\\cos\\left[(m+n) \\frac{\\pi x}{L}\\right] \\diff x - \\int_0^L\\cos\\left[(m-n) \\frac{\\pi x}{L}\\right] \\diff x = 0$$\n",
    "\n",
    "The integral of $\\varphi_m \\cdot \\varphi_n$ over the interval $[0,1]$ will always be zero, unless $m=n$ in which case it will be $\\int_0^L \\sin^2(n \\pi x)=L/2$. Now this relation in proper notation:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\int_0^L \\sin\\left(\\frac{m \\pi}{L} x\\right) \\cdot \\sin \\left(\\frac{n \\pi}{L} x\\right) dx=\\begin{cases}\n",
    "    \\frac{L}{2}, & \\text{if $m=n$}.\\\\\n",
    "    0, & \\text{if $m\\neq n$}.\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "We rely on this property to continue solving the heat equation for some arbitrary initial condition (and the wave equation as we'll see in [another notebook ](Waves.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2226793f-55f4-4ebf-bc46-7d147a354546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_n</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_n</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe38b2c280e44ffb7ab0aed2bb0af5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=5.0, description='N', max=20.0, min=1.0, step=1.0), Output()), _dom_cl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "plt.close()\n",
    "\n",
    "x = np.linspace(-2, 2, 500)\n",
    "ffull = x + 0.5 # the function f(x)\n",
    "N = 20\n",
    "\n",
    "lims = np.abs(x)<1 # define the interval [-pi, pi] for the Fourier series\n",
    "xl = x[lims]\n",
    "f = ffull[lims]  \n",
    "# initialise coefficients\n",
    "an = np.zeros(N)\n",
    "bn = np.zeros(N)\n",
    "\n",
    "# calculate coefficients an, bn\n",
    "for n in range(N):\n",
    "    an[n] = np.trapz(f*np.cos(np.pi*n*xl), xl)\n",
    "    bn[n] =  np.trapz(f*np.sin(np.pi*n*xl), xl)\n",
    "    \n",
    "data = np.round(np.vstack((an, bn)), 2)\n",
    "df = pd.DataFrame(data=data,   \n",
    "              index=('a_n','b_n'),    \n",
    "             columns=range(1,N+1))  \n",
    "\n",
    "display(HTML(df.to_html()))\n",
    "\n",
    "\n",
    "def update(Nlim):\n",
    "    # N is the number of coefficients\n",
    "    Nlim = int(Nlim)\n",
    "    \n",
    "    \n",
    "    # zeroth coefficient (could also include cos(0) term below instead)\n",
    "    \n",
    "    \n",
    "    fs = np.zeros_like(ffull) # initialise Fourier series \n",
    "\n",
    "    fs = fs + an[0]/2 # add zeroth term\n",
    "    \n",
    "    for n in range(1,Nlim):\n",
    "        fs = fs + an[n] * np.cos(np.pi*n*x) + bn[n] * np.sin(np.pi*n*x)\n",
    "        \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x,ffull, 'b', label='f(x)')\n",
    "    \n",
    "    ax.plot(x,fs, 'r', label='F.Series $[-1,1]$')\n",
    "    \n",
    "    ax.set_title('')\n",
    "    ax.set_axis_off()\n",
    "    ax.set_axis_off()\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.axvline(1, color='k')\n",
    "    ax.axvline(-1, color='k')\n",
    "    ax.axhline(0, color='k')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "interact(update, Nlim=widgets.FloatSlider(min=1, max=20, step=1, value=5, dtype=int, description='N')\n",
    "        );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668f58f-0744-4551-8c61-a9a34126bb60",
   "metadata": {},
   "source": [
    "Notice here that when $f$ and $g$ don't line up, the red and blue shaded areas of $f\\cdot g$ are equal! In an alternative view, the *phasors* $e^{i\\pi m x}$ and $e^{i\\pi n x}$ rotate at different speeds.\n",
    "\n",
    "## The solution\n",
    "\n",
    "Now we have a way of isolating each spatial harmonic. Let's go back to our temperature distribution and try to apply the initial condition, the shape $f(x)$ represented as its Fourier sum:\n",
    "\n",
    "$$f(x)=\\sum_{n=1}^{\\infty}A_n \\sin\\left(\\frac{n\\pi}{L} x\\right)$$\n",
    "\n",
    "Now we multiply both sides by $\\varphi_m(x)=\\sin\\left(\\frac{m\\pi}{L} x\\right)$, picking a single (integer) value of $m$:\n",
    "\n",
    "$$f(x){\\color{Red}\\cdot\\sin\\left(\\frac{m\\pi}{L} x\\right)}=\\sum_{n=1}^{\\infty}A_n \\sin\\left(\\frac{n\\pi}{L} x\\right){\\color{Red}\\cdot\\sin\\left(\\frac{m\\pi}{L} x\\right)}$$\n",
    "\n",
    "Now we integrate both sides over the interval $[0,L]$, remembering this is now the inner product $\\l:\n",
    "\n",
    "$$\\int_0^Lf(x){\\color{Red}\\cdot\\sin\\left(\\frac{m\\pi}{L} x\\right)} dx=\\int_0^L\\sum_{n=1}^{\\infty}A_n \\sin\\left(\\frac{n\\pi}{L} x\\right){\\color{Red}\\cdot\\sin\\left(\\frac{m\\pi}{L} x\\right)}dx $$\n",
    "\n",
    "Now, almost by magic, all but one of the terms in the sum on the right side vanish! Where $m\\neq n$, the integral of a term returns zero, and where $m=n$ it has a value of $A_n L/2$. On the left hand side, the integral remains (since we haven't specified $f(x)$). We can now, one at a time, plug in different values of $m$ and obtain a single equation without infinite sums (though we have traded this for infinite equations...):\n",
    "\n",
    "$$\\int_0^Lf(x){\\color{Red}\\cdot\\sin\\left(\\frac{m\\pi}{L} x\\right)} dx=\\frac{L}{2}A_m$$\n",
    "\n",
    "What's great here is that we now have a formula for the coefficients $A_n$:\n",
    "\n",
    "$$A_n = \\frac{2}{L}\\int_0^Lf(x){\\color{Red}\\cdot\\sin\\left(\\frac{n\\pi}{L} x\\right)} dx$$\n",
    "\n",
    "So here's our full temperature distribution:\n",
    "\n",
    "$$\n",
    "u(x,t)= \\sum_{n=1}^{\\infty}A_n \\sin\\left(k_n x\\right) e^{-D k_n^2 t}\n",
    "$$\n",
    "where $$A_n = \\frac{2}{L}\\int_0^Lf(x)\\sin\\left(\\frac{n\\pi}{L} x\\right) dx$$\n",
    "\n",
    "So to get the coefficients, we need to apply a transformation to the function $f(x)$ (which remember is our initial distribution). This allows us to represent $f(x)$ as a sum of harmonics. The shapes of the harmonics are fixed, but their amplitudes vary depending on the function. Some functions (like a simple sine wave $f(x)= \\sin(\\pi x)$ will only contain one harmonic. We can expect, by orthogonality, that in carrying out the transform for $\\sin(\\pi x)$ all coefficients but one will be zero.\n",
    "\n",
    "Thinking about our inner product analogy, we see that to find each coefficient $A_n$, we must find the inner product of the initial distribution $f(x)$ and each mode shape $\\sin\\left(\\frac{n\\pi}{L} x\\right)$. In other words, **how much of the frequency $k_n$ is contained in the distribution $f(x)$**.\n",
    "\n",
    "The beauty of this kind of decomposition is that lots of previously intractable solutions can be worked out and computed quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dadc70f-262d-4c4b-b853-a19c811a248b",
   "metadata": {},
   "source": [
    "\n",
    "## Towards the Fourier transform\n",
    "\n",
    "Nothing in our derivation so far is restricting how large the length of the rod $L$ can be. The orthogonality of sine functions should apply for any $L$, so we can ask ourselves what would happen if we increased $L$ indefinitely. We will find that the spatial frequencies come closer and closer together, since:\n",
    "\n",
    "$$k_n=\\frac{n \\pi}{L}$$\n",
    "\n",
    "Let's look at a few increasing values of $L$:\n",
    "\n",
    "\\begin{aligned}\n",
    "L = 1 &\\Rightarrow k_n = \\{\\pi, 2\\pi, 3\\pi, \\dots\\} \\\\\n",
    "L = 10 &\\Rightarrow k_n = \\left\\{\\frac{\\pi}{10}, \\frac{2\\pi}{10}, \\frac{3\\pi}{10}, \\dots\\right\\} \\\\\n",
    "L = 100 &\\Rightarrow k_n = \\left\\{\\frac{\\pi}{100}, \\frac{2\\pi}{100}, \\frac{3\\pi}{100}, \\dots\\right\\}\n",
    "\\end{aligned}\n",
    "\n",
    "As $L\\to \\infty$, the interval $\\Delta k=\\pi/L$ between successive modes becomes smaller, and the modes $k_n$ start to resemble a continuum $k$. Look at the complete Fourier series again:\n",
    "\n",
    "$$f(x)=\\sum_{n=0}^{\\infty} \\left[a_n \\cos\\left(k_n x\\right) +  b_n \\sin\\left(k_n x\\right)\\right]$$\n",
    "\n",
    "It's clear that as the spacing of each $k_n$ gets smaller, this sum will tend to look more and more like an integral.\n",
    "\n",
    "We know how to extract coefficients $a_n$ in terms of $k_n$ and $\\Delta k$. With reducing spacing we go from:\n",
    "\n",
    "\n",
    "$$a_n = \\frac{1}{L}\\int_{-L}^Lf(x)\\cdot\\cos\\left(\\frac{n\\pi}{L} x\\right) dx$$\n",
    "\n",
    "To the function $A(k_n)$:\n",
    "\n",
    "$$\n",
    "A(k_n)= \\frac{2\\Delta k}{\\pi} \\int_{-\\pi/\\Delta k}^{\\pi/\\Delta k} f(x) \\sin(k_n x) dx\n",
    "$$\n",
    "\n",
    "We'll define an amplitude function $F(k_n)=A_n/\\Delta k$. The units of $F(k_n)$ are of amplitude per unit frequency. As we reduce the spacing, the upper limit of integration goes to infinity. In the limit as $\\Delta k \\to 0$:\n",
    "\n",
    "$$F(k)=\\frac{1}{\\pi} \\int_0^{\\infty} f(x) \\cos(k x) dx$$\n",
    "\n",
    "And this is the Fourier cosine transform! $F(k)$ is the continuous analogue of the coefficients $b_n$ in our original Fourier series (Eq. 1), except the interval $[-L,L]$ has been extended to $[-\\infty, \\infty]$. It's still telling us how much of a given frequency is contained in the function $f(x)$, except we're looking at a continuous spectrum of frequencies from zero to infinity. We can also observe that, in many cases, the function $F(k)$ might have some trouble converging for even simple forms of $f(x)$. If $f(x)=1$ we're already in trouble as $\\int_0^{\\infty}\\cos(k x) \\diff x$ does not converge.   \n",
    "Let's go back and plug $F(k_n)$ into our Fourier cosine series for the function $f(x)$, still summing over discrete modes $k_n$ though they're getting closer and closer. Remembering that $F(k_n)=A(k_n)/\\Delta k$, we end up with: \n",
    "\n",
    "$$f(x)=\\sum_{k_n} F(k_n) \\cos\\left(k_n x\\right) \\Delta k$$\n",
    "\n",
    "This resembles a Riemann sum $\\sum_i f(x_i) \\Delta x_i$, and in the limit as $\\Delta k \\to 0$ we obtain the integral:\n",
    "\n",
    "$$f(x)=\\int_0^{\\infty} A(k) \\cos\\left(k x\\right) dk$$\n",
    "\n",
    "And we have obtained the inverse cosine transform by extending the Fourier series interval from $[-L,L]$ to $[-\\infty, \\infty]$. The same process is applied for the coefficients $b_n$ to get the same form. The Fourier transform of $f(x)$ is then the linear sum of sine and cosine transforms:\n",
    "\n",
    "\n",
    "$$f(x)=\\int_0^{\\infty} \\left[ A(k) \\cos\\left(k x\\right) + B(k) \\sin\\left(k x\\right)\\right] dk$$\n",
    "\n",
    "This is reconstructing the function $f(x)$ from the amplitude spectra $A(k)$ and $B(k)$ representing even and odd frequency components. This is \n",
    "\n",
    "So our transform formulas are:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{array}{ll}\n",
    "A(k)=\\frac{1}{\\pi} \\int_0^{\\infty} f(x) \\cos(k x) \\diff x \\\\\n",
    "B(k)=\\frac{1}{\\pi} \\int_0^{\\infty} f(x) \\sin(k x) \\diff x \\\\\n",
    "f(x)=\\int_0^{\\infty} \\left[ A(k) \\cos\\left(k x\\right) + B(k) \\sin\\left(k x\\right)\\right] \\diff k\n",
    "\\end{array}\n",
    "}\n",
    "$$\n",
    "\n",
    "This is not too compact, and could do better by using complex numbers as we'll see.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64117f84-9501-499c-b57c-eb5fe916671b",
   "metadata": {},
   "source": [
    "\n",
    "## The complex series\n",
    "\n",
    "If we work with complex numbers things get a bit neater. If $A$ and $B$ could be just a single coefficient $C$ that would be great.\n",
    "Let's just work with one term of the series $f_n(x)$ and for simplicity $k_n=\\frac{n\\pi}{L}$:\n",
    "\n",
    "$$f_n(x)= a_n \\cos {k_n x} + b_n\\sin k_n x$$ \n",
    "\n",
    "All quantities here are real numbers, $\\{f_n, a_n, b_n, k_n, x\\} \\in \\mathbb{R}$. We can introduce complex numbers without changing the output, by using a few substitutions. We can use the identities for $\\cos( k_n x)=\\frac{1}{2}(e^{ik_nx}+e^{-ik_nx})$ and $\\sin(k_n x)=\\frac{1}{2i}(e^{ik_nx}-e^{-ik_nx})$. The complex expressions here return real numbers. This is crucial, for $f(x)$ to be a real function, any imaginary parts would need to cancel on the RHS.\n",
    "\n",
    "By expanding we find that an equivalent form for the $n$th term is:\n",
    "\n",
    "$$f_n(x)= \\frac{1}{2}(a_n+ib_n) e^{i k_n x} + \\frac{1}{2}(a_n-ib_n)e^{-i k_n x}$$ \n",
    "\n",
    "Something interesting can be seen here: that $(a_n-ib_n)$ is the complex conjugate of $(a_n+ib_n)$, and $e^{-ik_nx}$ is the complex conjugate of $e^{ik_nx}$. Let's lump $(a_n+ib_n)/2$ into a single complex coefficient $c_n$:\n",
    "\n",
    "$$c_n=(a_n+ib_n)/2$$ \n",
    "\n",
    "This coefficient encodes our cosine and sine amplitudes in its real and imaginary parts respectively. Now:\n",
    "\n",
    "$$f_n(x)= c_n e^{i k_n x} + \\overline{c_n e^{i k_n x}}$$ \n",
    "\n",
    "With the overline indicating complex conjugation. We can see that each term in the series is a complex number added to its conjugate, meaning the imaginary parts would cancel out. We do this for every term in the series and so the total sum $f(x)$ is real. But now we're only dealing with one coefficient $c_n$ which is nice, and we could move to the more compact notation using $e^{i k_nx}$. Now the full series is in this form:\n",
    "\n",
    "$$f(x)= \\sum_{n=0}^{\\infty}\\left[c_n e^{i k_n x} + \\overline{c_n e^{i k_n x}}\\right]$$ \n",
    "\n",
    "We can do better though. We notice that if $n<0$ then the rightmost term would revert to $\\overline {e^{-i k_n x} }=e^{i k_n x}$.\n",
    "\n",
    "If we define negative indexed values of $c_n$ as its conjugates $c_{-n}=\\overline{c_n}$ then we can rewrite this expression as:\n",
    "\n",
    "$$f(x)= \\sum_{n=0}^{\\infty}c_n e^{i k_n x} + \\sum_{n=0}^{-\\infty} \\overline{c_{-n}} e^{i k_n x}$$ \n",
    "\n",
    "And now we finally have:\n",
    "\n",
    "$$f(x)= \\sum_{n=-\\infty}^{\\infty}c_n e^{i k_n x}$$ \n",
    "\n",
    "We have to be careful with what has happened to the coefficient $c_0$, which is $c_0=a_0/2=a_0\\cos(0)/2$. It's only counted once, whereas in the previous equation it should have appeared along with its conjugate $\\overline{c_0}$. The series above works well with our definition of $a_0$ according to Eq. 2. So provided we obtain $c_n$ from $f(x)$ are consistent with that, we should have no trouble! So how do we obtain $c_n$? We can just use Eqs. 2 and 3:\n",
    "\n",
    "$$c_n=\\frac{a_n + ib_n}{2} = \\frac{1}{2L} \\int_{-L}^{L} f(x) \\cosn \\diff x + i\\frac{1}{2L}\\int_{-L}^{L} f(x) \\sinn \\diff x$$\n",
    "\n",
    "Which simplifies to:\n",
    "$$\n",
    "c_n = \\frac{1}{2L} \\int_{-L}^{L} f(x) \\left(\\cosn \\diff x + i\\sinn\\right) \\diff x $$\n",
    "\n",
    "And, finally, Euler's formula strikes again:\n",
    "$$\n",
    "c_n =  \\frac{1}{2L} \\int_{-L}^{L} f(x) e^{i k_n x} \n",
    "$$\n",
    "\n",
    "So our series and coefficients are given by:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "c_n =  \\frac{1}{2L} \\int_{-L}^{L} f(x) e^{i k_n x} \\\\\n",
    "f(x)= \\sum_{n=-\\infty}^{\\infty}c_n e^{i k_n x}\n",
    "\\end{aligned}\n",
    "}$$\n",
    "\n",
    "Note that it is not at all necessary for $c_{-n}=\\overline{c_n}$. $c_{-n}$ could be any complex value. The conjugate symmetry is only required if we want to express a real function $f(x)$. The series can represent a complex function, in which case it will not exhibit this symmetry! \n",
    "\n",
    "It's important to note that, with a negative index, we have introduced are often termed *negative frequencies*: the terms $k_n = \\frac{n\\pi}{L}$ for $n<0$ which are negative.\n",
    "\n",
    "We have so far left something out in our earlier study of the Fourier series. Our vanilla, real Fourier series in Eq. 1 does not contain negative arguments for the sine and cosine functions. But why is that? The reason is fairly simple. We know that cosine and sine are symmetrical:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\cos(-x)&=\\cos(x) & \\text{(even)}\\\\\n",
    "\\sin(-x)&=-\\sin(x) & \\text{(odd)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The coefficients $a_n$ and $b_n$ obtained with the positive indices implicitly encode both sides of the spectrum due to the even and odd symmetry of cosine and sine functions. \n",
    "To show this explicitly, suppose we did extend the real Fourier series in Eq. 1 to include all the negative terms $n<0$. Then for some value of $n$ would have terms $f_n$ and $f_{-n}$ as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_n &= a_n \\cos(k_n x) + b_n \\sin(k_n x)\\\\\n",
    "f_{-n} &= a_{-n} \\cos(-k_n x)+b_{-n} \\sin(-k_n x) \\\\\n",
    "& = a_{-n} \\cos(k_n x)-b_{-n} \\sin(k_n x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where we have used the even/odd identities. Adding them together gives:\n",
    "\n",
    "$$\n",
    "f_n + f_{-n} = (a_n+a_{-n}) \\cos(k_n x) + (b_n - b_{-n}) \\sin(k_n x) = a_n \\cos(k_n x) + b_n \\sin(k_n x)\n",
    "$$\n",
    "\n",
    "So the total contribution is still in terms of the positive frequency basis functions, $\\cos(k_n x)$ and $\\sin(k_n x)$. There's no need to include the negative spectrum!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c66fa-e2f8-4943-a063-3ae54e56f5de",
   "metadata": {},
   "source": [
    "\n",
    "## More interesting boundaries\n",
    "\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
